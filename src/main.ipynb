{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "# The values 0.1307 and 0.3081 used for the Normalize() transformation below are the global mean and standard \n",
    "# deviation of the MNIST dataset. This is equivalent to scaling all pixel values between [0, 1].\n",
    "transform = torchvision.transforms.Compose([\n",
    "              torchvision.transforms.ToTensor(),\n",
    "              torchvision.transforms.Normalize(\n",
    "                (0.1307,), (0.3081,))\n",
    "            ])\n",
    "\n",
    "train_data = torchvision.datasets.MNIST('', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.MNIST('', train=False, download=True, transform=transform)\n",
    "\n",
    "# We can see some information about this data, including the transform we've applied.\n",
    "# train_data\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first 16 elements of the training set\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    ax = fig.add_subplot(4, 4, i + 1)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.imshow(train_data.data[i], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 28, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(28, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=400, out_features=1024, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (logsoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nn = torch.nn\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 28, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv1.weight.data.normal_(0, 0.0025)  \n",
    "        self.conv1.bias.data.fill_(0.1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(28, 16, kernel_size=5, stride=1)\n",
    "        self.conv2.weight.data.normal_(0, 0.0025)\n",
    "        self.conv2.bias.data.fill_(0.1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # First dense layer\n",
    "        self.fc1_units = 1024  \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, self.fc1_units)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Second dense layer\n",
    "        self.fc2_units = 128  \n",
    "        self.fc2 = nn.Linear(self.fc1_units, self.fc2_units)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.dropout_rate = 0.2\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "        \n",
    "        # Output dense layer\n",
    "        self.fc3_units = 10  \n",
    "        self.fc3 = nn.Linear(self.fc2_units, self.fc3_units)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.logsoftmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 28, 28, 28]             728\n",
      "              ReLU-2           [-1, 28, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 28, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]          11,216\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
      "           Flatten-7                  [-1, 400]               0\n",
      "            Linear-8                 [-1, 1024]         410,624\n",
      "              ReLU-9                 [-1, 1024]               0\n",
      "           Linear-10                  [-1, 128]         131,200\n",
      "             ReLU-11                  [-1, 128]               0\n",
      "          Dropout-12                  [-1, 128]               0\n",
      "           Linear-13                   [-1, 10]           1,290\n",
      "       LogSoftmax-14                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 555,058\n",
      "Trainable params: 555,058\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.43\n",
      "Params size (MB): 2.12\n",
      "Estimated Total Size (MB): 2.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "summary(model, (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function, accuracy and train/test algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data2 size: 54000\n",
      "val_data size: 6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PyTorch requires that we specify a device. This is the CPU or GPU that PyTorch will use to run the model.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# declare loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum = 0.9)\n",
    "\n",
    "\n",
    "# Split train into train2 and val\n",
    "percent_train2 = 0.9\n",
    "percent_val = 0.1\n",
    "\n",
    "size_train2 = int(len(train_data) * percent_train2)\n",
    "size_val = len(train_data) - size_train2\n",
    "\n",
    "train_data2, val_data = torch.utils.data.random_split(train_data, [size_train2, size_val])\n",
    "print(f'train_data2 size: {len(train_data2)}')\n",
    "print(f'val_data size: {len(val_data)}\\n')\n",
    "\n",
    "\n",
    "# load train2 and val data\n",
    "train_data2_loader = torch.utils.data.DataLoader(train_data2, batch_size=100)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size= len(val_data))\n",
    "\n",
    "# function to extract features and labels from a data loader\n",
    "def extract_features_and_labels(data_loader):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for features, labels in data_loader:\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "        # combine labels into a tensor\n",
    "        feature_tensor = torch.cat(all_features)\n",
    "        label_tensor = torch.cat(all_labels)\n",
    "    \n",
    "    return  feature_tensor, label_tensor\n",
    "\n",
    "# accuracy calculator\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# function to predict and classify\n",
    "def predict(model, data):\n",
    "    with torch.no_grad():\n",
    "        # Set the model to evaluation mode\n",
    "#         model.eval()\n",
    "        \n",
    "        # output probabilities\n",
    "        outputs = model.forward(data)\n",
    "        \n",
    "        # output classifications\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "    return predicted_classes\n",
    "\n",
    "# function to train model\n",
    "def train(num_epochs, model, train_data_loader, val_data_loader, optimizer, loss_function):\n",
    "    batch_count = 0\n",
    "    \n",
    "    # extract feature tensors for train data and val data\n",
    "    train_features = extract_features_and_labels(train_data_loader)[0]\n",
    "    train_labels = extract_features_and_labels(train_data_loader)[1]\n",
    "    \n",
    "    val_features = extract_features_and_labels(val_data_loader)[0]\n",
    "    val_labels = extract_features_and_labels(val_data_loader)[1]\n",
    "    \n",
    "     \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        for inputs, labels in train_data_loader:\n",
    "            batch_count += 1\n",
    "\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "            # make predictions\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "            # update gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_count%100 == 0:\n",
    "                print(f'batch {batch_count}, loss: {loss:.4f}')\n",
    "        \n",
    "        # predict train2 and val\n",
    "        train_pred = predict(model, train_features)\n",
    "        val_pred = predict(model, val_features)\n",
    "        \n",
    "        train_accuracy = accuracy(train_labels.numpy(), train_pred.numpy())\n",
    "        val_accuracy = accuracy(val_labels.numpy(), val_pred.numpy())\n",
    "        \n",
    "        acc_plot_data = []\n",
    "        acc_plot_data += [(epoch, train_accuracy, val_accuracy)]\n",
    "        \n",
    "        loss_plot_data = []\n",
    "        loss_plot_data += [(epoch, loss)]\n",
    "                \n",
    "        \n",
    "        print(f'\\nepoch {epoch}\\n'\n",
    "              f'training accuracy: {train_accuracy:.4f}, validation accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        return acc_plot_data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data2 size: 54000\n",
      "val_data size: 6000\n",
      "\n",
      "batch 100, loss: 2.2983\n",
      "batch 200, loss: 0.9992\n",
      "batch 300, loss: 0.3238\n",
      "batch 400, loss: 0.1268\n",
      "batch 500, loss: 0.3377\n",
      "\n",
      "epoch 1\n",
      "training accuracy: 0.9606, validation accuracy: 0.9587\n",
      "batch 600, loss: 0.2785\n",
      "batch 700, loss: 0.1421\n",
      "batch 800, loss: 0.0622\n",
      "batch 900, loss: 0.0135\n",
      "batch 1000, loss: 0.1506\n",
      "\n",
      "epoch 2\n",
      "training accuracy: 0.9809, validation accuracy: 0.9780\n",
      "batch 1100, loss: 0.0367\n",
      "batch 1200, loss: 0.0588\n",
      "batch 1300, loss: 0.0389\n",
      "batch 1400, loss: 0.0102\n",
      "batch 1500, loss: 0.0210\n",
      "batch 1600, loss: 0.0931\n",
      "\n",
      "epoch 3\n",
      "training accuracy: 0.9866, validation accuracy: 0.9823\n",
      "batch 1700, loss: 0.0081\n",
      "batch 1800, loss: 0.0318\n",
      "batch 1900, loss: 0.0553\n",
      "batch 2000, loss: 0.0312\n",
      "batch 2100, loss: 0.0074\n",
      "\n",
      "epoch 4\n",
      "training accuracy: 0.9875, validation accuracy: 0.9818\n",
      "batch 2200, loss: 0.0185\n",
      "batch 2300, loss: 0.1438\n",
      "batch 2400, loss: 0.0320\n",
      "batch 2500, loss: 0.0814\n",
      "batch 2600, loss: 0.0871\n",
      "batch 2700, loss: 0.0263\n",
      "\n",
      "epoch 5\n",
      "training accuracy: 0.9917, validation accuracy: 0.9842\n",
      "batch 2800, loss: 0.0230\n",
      "batch 2900, loss: 0.0430\n",
      "batch 3000, loss: 0.0141\n",
      "batch 3100, loss: 0.0452\n",
      "batch 3200, loss: 0.0459\n",
      "\n",
      "epoch 6\n",
      "training accuracy: 0.9910, validation accuracy: 0.9852\n",
      "batch 3300, loss: 0.0575\n",
      "batch 3400, loss: 0.0187\n",
      "batch 3500, loss: 0.0045\n",
      "batch 3600, loss: 0.0002\n",
      "batch 3700, loss: 0.0309\n",
      "\n",
      "epoch 7\n",
      "training accuracy: 0.9906, validation accuracy: 0.9838\n",
      "batch 3800, loss: 0.0016\n",
      "batch 3900, loss: 0.0454\n",
      "batch 4000, loss: 0.0112\n",
      "batch 4100, loss: 0.0046\n",
      "batch 4200, loss: 0.0217\n",
      "batch 4300, loss: 0.0291\n",
      "\n",
      "epoch 8\n",
      "training accuracy: 0.9941, validation accuracy: 0.9860\n",
      "batch 4400, loss: 0.0030\n",
      "batch 4500, loss: 0.0140\n",
      "batch 4600, loss: 0.0085\n",
      "batch 4700, loss: 0.0015\n",
      "batch 4800, loss: 0.0014\n",
      "\n",
      "epoch 9\n",
      "training accuracy: 0.9953, validation accuracy: 0.9882\n",
      "batch 4900, loss: 0.0010\n",
      "batch 5000, loss: 0.0195\n",
      "batch 5100, loss: 0.0039\n",
      "batch 5200, loss: 0.0407\n",
      "batch 5300, loss: 0.0054\n",
      "batch 5400, loss: 0.0092\n",
      "\n",
      "epoch 10\n",
      "training accuracy: 0.9951, validation accuracy: 0.9880\n",
      "batch 5500, loss: 0.0018\n",
      "batch 5600, loss: 0.0127\n",
      "batch 5700, loss: 0.0105\n",
      "batch 5800, loss: 0.0016\n",
      "batch 5900, loss: 0.0322\n",
      "\n",
      "epoch 11\n",
      "training accuracy: 0.9952, validation accuracy: 0.9848\n",
      "batch 6000, loss: 0.0276\n",
      "batch 6100, loss: 0.0049\n",
      "batch 6200, loss: 0.0029\n",
      "batch 6300, loss: 0.0001\n",
      "batch 6400, loss: 0.0054\n",
      "\n",
      "epoch 12\n",
      "training accuracy: 0.9943, validation accuracy: 0.9833\n",
      "batch 6500, loss: 0.0038\n",
      "batch 6600, loss: 0.0039\n",
      "batch 6700, loss: 0.0043\n",
      "batch 6800, loss: 0.0014\n",
      "batch 6900, loss: 0.0006\n",
      "batch 7000, loss: 0.0010\n",
      "\n",
      "epoch 13\n",
      "training accuracy: 0.9954, validation accuracy: 0.9863\n",
      "batch 7100, loss: 0.0001\n",
      "batch 7200, loss: 0.0027\n",
      "batch 7300, loss: 0.0005\n",
      "batch 7400, loss: 0.0044\n",
      "batch 7500, loss: 0.0028\n",
      "\n",
      "epoch 14\n",
      "training accuracy: 0.9955, validation accuracy: 0.9865\n",
      "batch 7600, loss: 0.0003\n",
      "batch 7700, loss: 0.0028\n",
      "batch 7800, loss: 0.0008\n",
      "batch 7900, loss: 0.0222\n",
      "batch 8000, loss: 0.0362\n",
      "batch 8100, loss: 0.0116\n",
      "\n",
      "epoch 15\n",
      "training accuracy: 0.9973, validation accuracy: 0.9887\n",
      "batch 8200, loss: 0.0007\n",
      "batch 8300, loss: 0.0022\n",
      "batch 8400, loss: 0.0009\n",
      "batch 8500, loss: 0.0031\n",
      "batch 8600, loss: 0.0077\n",
      "\n",
      "epoch 16\n",
      "training accuracy: 0.9977, validation accuracy: 0.9882\n",
      "batch 8700, loss: 0.0071\n",
      "batch 8800, loss: 0.0014\n",
      "batch 8900, loss: 0.0015\n",
      "batch 9000, loss: 0.0000\n",
      "batch 9100, loss: 0.0005\n",
      "\n",
      "epoch 17\n",
      "training accuracy: 0.9969, validation accuracy: 0.9888\n",
      "batch 9200, loss: 0.0054\n",
      "batch 9300, loss: 0.0014\n",
      "batch 9400, loss: 0.0012\n",
      "batch 9500, loss: 0.0000\n",
      "batch 9600, loss: 0.0022\n",
      "batch 9700, loss: 0.0039\n",
      "\n",
      "epoch 18\n",
      "training accuracy: 0.9966, validation accuracy: 0.9882\n",
      "batch 9800, loss: 0.0003\n",
      "batch 9900, loss: 0.0058\n",
      "batch 10000, loss: 0.0004\n",
      "batch 10100, loss: 0.0003\n",
      "batch 10200, loss: 0.0000\n",
      "\n",
      "epoch 19\n",
      "training accuracy: 0.9982, validation accuracy: 0.9888\n",
      "batch 10300, loss: 0.0001\n",
      "batch 10400, loss: 0.0001\n",
      "batch 10500, loss: 0.0004\n",
      "batch 10600, loss: 0.0010\n",
      "batch 10700, loss: 0.0009\n",
      "batch 10800, loss: 0.0005\n",
      "\n",
      "epoch 20\n",
      "training accuracy: 0.9986, validation accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  \n",
    "\n",
    "# train model on train2 data and return classifications and loss\n",
    "accuracy_plot_data, loss_plot_data = train(num_epochs, model, train_data2_loader, val_data_loader, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100, loss: 2.2854\n",
      "batch 200, loss: 2.3195\n",
      "batch 300, loss: 2.3159\n",
      "batch 400, loss: 2.3049\n",
      "batch 500, loss: 2.3123\n",
      "batch 600, loss: 2.3172\n",
      "batch 700, loss: 2.3065\n",
      "batch 800, loss: 2.3119\n",
      "batch 900, loss: 2.3193\n",
      "batch 1000, loss: 2.3147\n",
      "batch 1100, loss: 2.2970\n",
      "batch 1200, loss: 2.3000\n",
      "batch 1300, loss: 2.2971\n",
      "batch 1400, loss: 2.3060\n",
      "batch 1500, loss: 2.3122\n",
      "batch 1600, loss: 2.3208\n",
      "batch 1700, loss: 2.3093\n",
      "batch 1800, loss: 2.3027\n",
      "\n",
      "epoch 1\n",
      "training accuracy: 0.0963, validation accuracy: 0.0980\n"
     ]
    }
   ],
   "source": [
    "# initialise fresh model\n",
    "model2 = CNN()\n",
    "\n",
    "# load mnist train and test data\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data))\n",
    "\n",
    "train_features = extract_features_and_labels(train_data_loader)[0]\n",
    "train_labels = extract_features_and_labels(train_data_loader)[1]\n",
    "\n",
    "test_features = extract_features_and_labels(test_data_loader)[0]\n",
    "test_labels = extract_features_and_labels(test_data_loader)[1]\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "# train\n",
    "plot_data = train(num_epochs, model2, train_data_loader, test_data_loader, optimizer, loss_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and accuracy reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred\n",
    "test_pred = predict(model2, test_features)\n",
    "test_accuracy = accuracy(test_labels.numpy(), test_pred.numpy())\n",
    "\n",
    "train_pred = predict(model, train_features)\n",
    "train_accuracy = accuracy(train_labels.numpy(), test_pred.numpy())\n",
    "\n",
    "print('test accuracy: ', test_accuracy)\n",
    "print('train accuracy: ', train_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
